import os
import json
import numpy as np
import shutil
from nuscenes.nuscenes import NuScenes
from pyquaternion import Quaternion
from PIL import Image
import random

def convert_nuscenes_to_nerf(dataroot, version="v1.0-mini", camera_name="CAM_FRONT", output_dir='./nerf_data', num_samples=404):
    """
    Convert NuScenes CAM_FRONT data into NeRF Synthetic format with a custom dataset split.
    Training: 90% (20% é holdout, 70% holdout)
    Validation: 10%
    """
    if not os.path.exists(dataroot):
        raise FileNotFoundError(f"âŒ NuScenes æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataroot}")

    print(f"ğŸ“‚ Loading NuScenes dataset from: {dataroot}")
    nusc = NuScenes(version=version, dataroot=dataroot, verbose=True)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    images_dir = os.path.join(output_dir, 'images')
    os.makedirs(images_dir, exist_ok=True)

    frames = []

    # å¤„ç†æ•°æ®
    for sample_idx in range(min(num_samples, len(nusc.sample))):
        sample = nusc.sample[sample_idx]
        camera_data = nusc.get('sample_data', sample['data'][camera_name])
        image_path = os.path.join(dataroot, camera_data['filename'])

        # è½¬æ¢ JPG ä¸º PNG å¹¶ä¿å­˜
        img = Image.open(image_path)
        output_image_path = os.path.join(images_dir, f'r_{sample_idx}.png')
        img.save(output_image_path)

        # è¯»å–ç›¸æœºå†…å‚
        calib_data = nusc.get('calibrated_sensor', camera_data['calibrated_sensor_token'])
        intrinsics = np.array(calib_data['camera_intrinsic'])
        focal_length = intrinsics[0, 0]
        image_width = camera_data['width']
        camera_angle_x = 2 * np.arctan(image_width / (2 * focal_length))

        # è¯»å–ç›¸æœºä½å§¿
        ego_pose = nusc.get('ego_pose', camera_data['ego_pose_token'])
        ego_translation = np.array(ego_pose['translation'])
        ego_rotation = Quaternion(ego_pose['rotation']).rotation_matrix

        calib_translation = np.array(calib_data['translation'])
        calib_rotation = Quaternion(calib_data['rotation']).rotation_matrix

        # è®¡ç®—ç›¸æœºåˆ°ä¸–ç•Œåæ ‡çš„å˜æ¢çŸ©é˜µ
        global_rotation = ego_rotation @ calib_rotation
        global_translation = ego_rotation @ calib_translation + ego_translation

        transform_matrix = np.eye(4)
        transform_matrix[:3, :3] = global_rotation.T
        transform_matrix[:3, 3] = -global_rotation.T @ global_translation

        # äº¤æ¢ Y-Z è½´ï¼Œä½¿å…¶é€‚é… NeRF
        swap_yz = np.array([[1, 0, 0, 0], [0, 0, 1, 0], [0, -1, 0, 0], [0, 0, 0, 1]])
        transform_matrix = swap_yz @ transform_matrix

        # è®°å½•åˆ° frames åˆ—è¡¨
        frames.append({
            'file_path': f'./images/r_{sample_idx}',
            'rotation': 0,
            'transform_matrix': transform_matrix.astype(np.float32).tolist()
        })

    # æ•°æ®é›†åˆ’åˆ†ï¼š
    # è®­ç»ƒé›† (90%) â†’ 20% é holdout, 70% holdout
    # éªŒè¯é›† (10%)

    random.shuffle(frames)
    num_train = int(0.9 * len(frames))
    num_val = int(0.1 * len(frames))

    train_frames = frames[:num_train]  # 90% è®­ç»ƒæ•°æ®
    val_frames = frames[num_train:num_train + num_val]  # 10% éªŒè¯æ•°æ®

    # è¿›ä¸€æ­¥åˆ’åˆ† è®­ç»ƒé›† â†’ 20% é holdout, 70% holdout
    num_train_non_holdout = int(0.2 * len(train_frames))  # 20% ç›´æ¥è®­ç»ƒ
    train_non_holdout = train_frames[:num_train_non_holdout]  # å›ºå®šè®­ç»ƒæ•°æ®
    train_holdout = train_frames[num_train_non_holdout:]  # éœ€è¦ Active Learning é€‰å–çš„è®­ç»ƒæ•°æ®

    # è®­ç»ƒå…¨é›† = é holdout + holdout
    train_all = train_non_holdout + train_holdout

    # ä¿å­˜ JSON æ–‡ä»¶
    def save_json(filename, frames_data):
        with open(os.path.join(output_dir, filename), "w") as f:
            json.dump({
                'camera_angle_x': camera_angle_x,
                'frames': frames_data
            }, f, indent=4)
        print(f"âœ… Saved {filename}")

    save_json('transforms_train.json', train_non_holdout)  # è®­ç»ƒé›†ï¼ˆ20% é holdoutï¼‰
    save_json('transforms_holdout.json', train_holdout)  # è®­ç»ƒé›†ï¼ˆ70% holdoutï¼‰
    save_json('transforms_trains.json', train_all)  # è®­ç»ƒå…¨é›†ï¼ˆ90% = 20% é holdout + 70% holdoutï¼‰
    save_json('transforms_val.json', val_frames)  # éªŒè¯é›†ï¼ˆ10%ï¼‰

    print(f"âœ… Conversion complete! Data saved to {output_dir}")

if __name__ == "__main__":
    # ä½ å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹ `dataroot` ä»¥åŒ¹é…ä½ çš„ NuScenes æ•°æ®é›†è·¯å¾„
    convert_nuscenes_to_nerf(
        dataroot = r'/root/autodl-tmp/GNT-code/GNT-code/v1.0-mini',  # âš ï¸ ä¿®æ”¹ä¸ºNuScenes æ•°æ®è·¯å¾„
        version="v1.0-mini",
        camera_name="CAM_FRONT",  # å¯ä»¥æ”¹æˆ 'CAM_FRONT_LEFT', 'CAM_FRONT_RIGHT' ç­‰
        output_dir="/root/autodl-tmp/GNT-code/GNT-code/nerf_synthetic/nerf_data",  # NeRF æ•°æ®å­˜æ”¾ä½ç½®
        num_samples=404  # mini ç‰ˆæœ€å¤š 404 å¼ å›¾
    )
